# 3. 빅데이터 모델링 

## 1. 분석 모형 설계 
- 데이터 분류 방법 
  1. 홀드 아웃(hold - out) : 랜덤하게 train/ train set을 분리
  2. 교차 검증(cross-validation) : k개로 분리한 데이터를 순차적로 학습하여 얻어낸 k개의 MSE값들을 평균내어 최종적으로 사용 
## 2. 분석기법 적용
- 회귀분석 
  : 주관식(연속적인 데이터 형태)
  : 독립변수(입력값, 원인)로 종속변수(결과값, 효과)를 예측하는 기법
- 선형회귀분석의 가정 
  : 선형성, 독립성, 등분산성, 비상관성, 정상성
1. 단순 선형회귀
	  Y<sub>i</sub> = β<sub>0</sub>+ β<sub>1</sub>x<sub>1</sub>+ε<sub>i</sub> : 독립 변수가 1개 
	  (Y : 종속 변수)
	  (X : 독립 변수)
	  (β<sub>0</sub> : 절편)
	  (β<sub>1</sub> : 기울기)
	  (ε<sub>i</sub> : 오차항)
	- 회귀계수 추정방법 : 최소제곱법(최소자승법)
	 $$ \text{RSS} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 $$
	 - 단순 선형회귀분석 결과해석
	   : F 통계량은 p-value가 유의수준 0.05보다 작다면 귀무가설(β<sub>1</sub> = 0) 기각, 대립 가설 선택
	-  회귀 계수는 통계적으로 유의한가?(t-검정)
	  : p-value가 0.05보다 작거나 t-통계량의 절댓값이 2보다 크면 귀무가설을 기각하고 통계적으로 유의하다고 판단가능
	  - 모형은 데이터를 얼마나 설명할 수 있는가? 
	    R^2 : 결정계수가 1에 가까울수록 설명력이 높다고 판단
	- 모형이 데이터를 잘 적합하고 있는가? 
	  : 잔차를 그래프로 그리고 회귀진단을 수행하여 판단 

2. 다중 선형 회귀
   $$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \epsilon $$
   : 2개 이상의 독립변수
   : 다중 공정성의 문제 발생  : 독립변수들 간의 강한 상관관계가 정확한 회귀계수 추정을 방해
	   : 독립변수들 간의 상관계수를 구함
	   : 허용오차를 구함(0.1이하면 문제 심각)
	   : 분산팽창요인 구함(VIF) (10이하면 문제 심각)

3. 최적 회귀방정식 선택
   - 전진선택법 : 변수의 수가 많은 경우 사용 가능, 안정성 부족 및 선택된 변수 제거 불가 
   - 후진제거법 : 전체 변수의 정보 이용, 변수 수가 많은 경우 사용이 어렵고 변수 제거 불가 
   - 단계적 방법 : 전진+ 후진 : 모든 변수조합 고려가능, 계산량이 많아짐
4. 수정된 결정계수
   - MSE(평균 제곱 오차)값이 최소인 시점의 모형을 선택
5. Mallow's Cp
   : 변수가 많이 추가될수록 RSS는 작아지며, RSS가 최소인 모형을 선택한다는 것은 모든 변수를 갖는 모델을 선택한 것. 
   : Mallow's Cp는 모든 변수를 선택한 모델과 p개의 변수를 선택한 모델의 차이를 비교하는 통계량이며 그 값이 비슷하다면 더 적은 변수의 수를 갖는 모델을 택함. 
6. 정규화 선형 회귀 -> 임베디드 방법
   : 선형회귀계수에 제약조건을 추가해 모델의 과적합을 방지(계수의 크기를 제한하는 방법)
   1) 릿지 회귀 : L2 penalty : 모든 가중치들의 제곱합을 최소화
   2) 라쏘 회귀 : L1 penalty : 모든 가중치 절대값들의 합을 최소화
   3) 엘라스틱 넷 : 릿지 + 라쏘 
      - 랜덤 성분 : 종속 변수의 분포에서 나타나는 잔차
      - 체계적 성분 : 종속 변수의 변동을 설명, 선형 예측자
      - 연결 함수 : 선형 예측자와 예측값 사이의 관계를 정의 
7. 회귀분석의 영향력 진단
   - 영향점 : 회귀직선의 기울기에 영향을 크게 주는 점. 회귀식에 나쁜 영향
   - 영향력 진단 방법 : 기준값보다 클 경우 영향점으로 간주
   - Cook's Distance, DFBETAS, DFFITS, Leverage H
     
### 1. 범주형 자료 분석
1. 분할표분석

|           | success | fail |
| --------- | ------- | ---- |
| exposed   | a       | b    |
| unexposed | c       | d    |
- 상대적 위험도 (RR: Relative Risk)
  =$\frac{\frac{a}{(a+b)}}{\frac{c}{(c+d)}}$
- 오즈비(Odds Ratio)
  Odds = $\frac{\text{Odds(exposed)}}{\text{Odds(unexposed)}} = \frac{\frac{a}{b}}{\frac{c}{d}}$
  = 주어진 환경에서 발생할 확률(p) / 주어진 환경에서 발생하지 않을 확률(1-p)
  = 노출되었을 때 발생할 확률이 그렇지 않을 때보다 Odds ratio배 높은 경향이 있다. 

2. 교차 분석
- 카이제곱 검정 : 두 변수 간의 관계를 알아보기 위함
     (적합성 검정, 독립성 검정, 동질성 검정에 사용됨)
     $$ \chi^2 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i} $$
     자유도(df) = k -1
	1) 적합성 검정
	  : 관측값들이 예상과 일치하는지 검정 
	2) 독립성 검정
	   : 변수들 사이에 관계가 독립인지 검정
	   $$ \chi^2 = \sum_{i=1}^{r} \sum_{j=1}^{c} \frac{(O_{ij} - E_{ij})^2}{E_{ij}} $$
	   자유도(df) = (r-1)(c-1)
	3) 동질성 검정
	   : 범주화된 집단의 분포가 동일한지 검정
	   : 계산은 독립성 검정과 동일
	   
3. 다차원척도법 
   : 개체들 사이의 유사성/ 비유사성을 측정하여 개체를 2, 3차원 공간에 점으로 표현해 개체간 근접성과 집단화를 시각화

- 다차원척도법의 목적 
  : 데이터 속 잠재된 패턴을 발견하고 공간에 기하학적으로 표현
  : 데이터 축소의 목적, 데이터정보발견을 위한 탐색수단
  : 데이터가 만들어진 현상이나 과정에 고유의 구조로 의미 부여
1) 다차원척도법 종류
   - 계량적 MDS : 데이터가 구간척도나 비율척도인 경우 사용
   - 비계량적 MDS : 데이터가 순서척도인 경우 사용

4. 다변량분석
   : 한 번에 분석하는 통계적 기법
   : 3차원 공간상의 입체적 표현이 필요
   : 여러 변인들간의 선형조합으로 해석
   1) 주성분분석(PCA)
      : 여러 변수들이 있을 때, 서로 상관성이 높은 변수에 변수들을 요약 및 축소하는 기법
  2) 주성분분석의 목적
     : 차원을 축소함으로써 데이터의 이해와 관리가 쉬워짐
     : 다중공산성문제 해결 
     : 군집분석수행해 연산속도 개선
  3) 주성분선택
     - 주성분기억율 : 주성분분석의 분산으로 총변동에 대한 설명력(누적 기여율이 85%이상이 되는 지점까지 주성분 선택)
     - scree plot : 주성분을 x축, 주성분의 고유값을 y축에 둔 그래프( 고유값이 급격히 완만해지는 지점의 전단계까지 주서운 선택) 
     - 전체변이공헌도
     - 평균고유값
  4) 특이값 분해
     : 주어진 행렬 M을 동일한 크기를 갖는 행렬로 분해
     : 큰 몇 개의 특이값으로 충분히 유용한 정보를 유지할 수 있는 차원을 생성 : 차원 축소
	-  요인분석
		  : 변수들의 상관관계를 고려해 유사한 변수들을 묶어 새로운 잠재요인들을 추출, 즉, 변수를 축소하고 데이터를 요약 
		  : 변수가 간격/비율축소여야 하며 표본은 100개 이상이 바람직(최소 50개 이상)
		  : 요인(새롭게 생성한 변수집단), 요인 적재값(변수와 요인간 상관계수), 요인행렬, 고유값, 공통성
		  
		  - 요인추출 방법
		    : 주성분분석/공통요인분석 -> 고유값 1이상에 해당하는 요인들 추출
		 -  요인분석 절차
			   : 데이터 입력 -> 상관계수산출 -> 요인추출 -> 요인적재량 산출 -> 요인회전 -> 생성된 요인해석 -> 요인점수 산출 
	- 판별분석
		  : 집단을 구별할 수 있는 판별함수 및 판별 규칙을 만들어 개체가 어느 집단에 속하는지 분류하는 다변량 기법 
		  : 독립 변수 -> 간격/비율 척도
		  : 종속 변수 -> 명목/순서 척도
  5) 시계열 분석
     1. 정상성
        : 시계열의 확률적인 성질들이 시간의 흐름에 변하지 않음을 의미
        1) 평균이 일정  : 모든 시점에 대해 일정, 차분을 통해 정상화
        2) 분산이 일정 : 시점에 의존X, 변환을 통해 정상화
        3) 공분산은 시차에만 의존, 특정 시점에 의존 X
	2. 이동평균법
		   : 과거부터 현재까지의 자료를 대상으로 일정기간별 이동평균을 계산하고 이들의 추세를 파악해 다음 기간을 예측
		   : 쉽게 미래 예측 가능
		   : 특정기간에 속한 시계열에 동일한 가중치 부여
	3. 지수평할법
		   : 모든 시계열자료를 사용해 평균을 구하고, 최근 시계열에 더 많은 가중치를 부여. 중기예측 이상에 주로 사용
	4. 자기 회귀모형(AR)
		   : 자기 상관성을 시계열 모형으로 구성한 것
	5. 이동평균모형(MA)
		   : 시간이 지날수록 관측치의 평균값이 지속적으로 증가하거나 감소하는 경향을 표현, 언제나 정상성 만족 
	6. 분해시계열
	   - 추세 변동: 장기적으로 나타나는 추세경향
	   - 계절 변동 : 일정한 주기로 반복적인 패턴을 보임
	   - 순환 변동 : 알려지지 않은 주기를 가지고 변함
	   - 불규칙변동 : 불규칙하게 우연적으로 발생 
	   - 시계열데이터 분석 절차
		    : 시간 그래프 작성 - 추세, 계절성 제거 - 잔차 예측 - 잔차에 대한 모델 적합 - 예측된 잔차에 추세, 계정성 더해 미래 예측 
5. 비모수통계

|      | 모수                          | 비모수                                       |
| ---- | --------------------------- | ----------------------------------------- |
| 가설설정 | 모집단에 대한 분포를 가정 모수에 대한 가설 설정 | 모집단분포에 아무런 제약 가하지 않음 가정된 분포가 없고 분포의 형태 설정 |
| 검정방법 | 표본평균, 표본 분산 이용해 검정 실시       | 절대적 크기가 없는 관측 값 순위나 값차이 부호를 이용해 검정        |
	- Kolmogorov - Smirnov test(단일표본)
	  : 관측치들이 **특정한 분포를 따르는지**에 대한 검정
	  : H0 : 주어진 분포는 a분포를 따른다 <-> H1 : 따르지 않는다.
	- Mann- whitney U test(독립 두 표본)
	  : 두 집단의 **분포**가 동일한지를 조사
	  : H0 : 두 집단의 순위합은 동일하다<-> H1 : 동일하지 않다.
	- Wilcoxon signed-rank test(대응 두 표본)
	  : 대응되는 두 데이터의 **중위수** 차이가 있는지를 검정
	  : H0 : 두 집단의 중앙값은 동일하다 <-> H1 : 동일하지 않다. 
	- Run test 
	  : 일련의 관측값들이 임의적으로 나타난 것인지 검정(우연성 검정)
6. 정형데이터 분석 기법 
   - 분류분석
     $$ p = \frac{\exp{(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p)}}{1 + \exp{(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p)}} $$
  - 의사결정 트리
    1) 성장단계
       이산형 : 카이제곱 통계량, 지니지수, 엔트로피지수
       연속형 : F통계량, 분산의 감소량
    2) 가지치기 단계
    3) 타당성 평가 : 이익도표/ 위험도표/ 시험용데이터
    4) 해석 및 예측 
    - 의사 결정 나무 알고리즘

| CART          | C4.5와 C5.0 | CHAID        |
| ------------- | ---------- | ------------ |
| 범주/연속         | 범주         | 범주/연속        |
| 지니지수<br>분산감소량 | 엔트로피지      | 카이제곱<br>F 검정 |
| 이진분리          | 다지분리       | 다지분리         |
- SVM(Support Vector Machine)
  : 패턴인식, 자료분석을 위한 지도학습 머신러닝 모델 
- kNN
  : 새로운 데이터를 어떤 범주로 분류할지 결정하는 지도학습
  : k 개수 선택 : 훈련 데이터 개수의 제곱근
  : 거리계산법 : 유클리디안, 맨하탄, 민코우스키 등
- Naive Bayes Classification
  : 데이터에서 변수들에 대한 조건부 독립을 가정하는 알고리즘 
  : 베이즈 정리 : 두 확률 변수의 사전확률과 사후확률 사이의 관계 
	  p(A|B) = p(B|A)p(A)/p(B)
	: 클래스 조건 독립성 
- Ensemble(앙상블)
  

